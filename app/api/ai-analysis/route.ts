import { NextRequest, NextResponse } from 'next/server'

interface AnalysisRequest {
  content: string
  title: string
  clipId: string
}

interface SectionSummary {
  id: string
  title: string
  summary: string
  anchor: string
  level: number
}

interface AnalysisResponse {
  quickSummary: string
  detailedSummary: string
  sections: SectionSummary[]
  error?: string
}

// ä½¿ç”¨OpenAI APIç”Ÿæˆæ‘˜è¦
async function generateAISummary(content: string, title: string, type: 'quick' | 'detailed'): Promise<string> {
  const apiKey = process.env.OPENAI_API_KEY
  const baseUrl = process.env.OPENAI_BASE_URL || 'https://api.openai.com/v1'
  const model = process.env.OPENAI_MODEL_GPT || 'gpt-4o-mini'

  if (!apiKey) {
    console.warn('OpenAI API Keyæœªé…ç½®ï¼Œä½¿ç”¨æ¨¡æ‹Ÿæ‘˜è¦')
    return generateFallbackSummary(content, title, type)
  }

  // æ¸…ç†å†…å®¹
  const cleanContent = content.replace(/<[^>]*>/g, ' ').replace(/\s+/g, ' ').trim()
  
  // é™åˆ¶å†…å®¹é•¿åº¦ä»¥é¿å…è¶…å‡ºtokené™åˆ¶
  const maxContentLength = type === 'quick' ? 2000 : 4000
  const truncatedContent = cleanContent.length > maxContentLength 
    ? cleanContent.slice(0, maxContentLength) + '...' 
    : cleanContent

  const prompt = type === 'quick' 
    ? `è¯·ä¸ºä»¥ä¸‹æ–‡æ¡£ç”Ÿæˆä¸€ä¸ª50å­—ä»¥å†…çš„æé€Ÿæ‘˜è¦ï¼Œè¦æ±‚ç®€æ´æ˜äº†ï¼Œçªå‡ºæ ¸å¿ƒè¦ç‚¹ï¼š

æ–‡æ¡£æ ‡é¢˜ï¼š${title}
æ–‡æ¡£å†…å®¹ï¼š${truncatedContent}

è¯·ç›´æ¥è¿”å›æ‘˜è¦å†…å®¹ï¼Œä¸è¦åŒ…å«"æ‘˜è¦ï¼š"ç­‰å‰ç¼€ã€‚`
    : `è¯·ä¸ºä»¥ä¸‹æ–‡æ¡£ç”Ÿæˆä¸€ä¸ª200å­—ä»¥å†…çš„è¯¦ç»†æ‘˜è¦ï¼Œè¦æ±‚å…¨é¢å‡†ç¡®ï¼ŒåŒ…å«ä¸»è¦è§‚ç‚¹å’Œä»·å€¼ï¼š

æ–‡æ¡£æ ‡é¢˜ï¼š${title}
æ–‡æ¡£å†…å®¹ï¼š${truncatedContent}

è¯·ç›´æ¥è¿”å›æ‘˜è¦å†…å®¹ï¼Œä¸è¦åŒ…å«"æ‘˜è¦ï¼š"ç­‰å‰ç¼€ã€‚`

  try {
    console.log(`ğŸ¤– è°ƒç”¨OpenAI APIç”Ÿæˆ${type === 'quick' ? 'æé€Ÿ' : 'è¯¦ç»†'}æ‘˜è¦...`)
    
    const response = await fetch(`${baseUrl}/chat/completions`, {
      method: 'POST',
      headers: {
        'Authorization': `Bearer ${apiKey}`,
        'Content-Type': 'application/json',
      },
      body: JSON.stringify({
        model: model,
        messages: [
          {
            role: 'user',
            content: prompt
          }
        ],
        max_tokens: type === 'quick' ? 100 : 300,
        temperature: 0.3,
      }),
    })

    if (!response.ok) {
      const errorText = await response.text()
      console.error(`OpenAI APIè°ƒç”¨å¤±è´¥: ${response.status} ${response.statusText}`, errorText)
      throw new Error(`OpenAI APIé”™è¯¯: ${response.status}`)
    }

    const data = await response.json()
    
    if (!data.choices || !data.choices[0] || !data.choices[0].message) {
      console.error('OpenAI APIè¿”å›æ ¼å¼å¼‚å¸¸:', data)
      throw new Error('OpenAI APIè¿”å›æ ¼å¼å¼‚å¸¸')
    }

    const summary = data.choices[0].message.content.trim()
    console.log(`âœ… ${type === 'quick' ? 'æé€Ÿ' : 'è¯¦ç»†'}æ‘˜è¦ç”ŸæˆæˆåŠŸ: ${summary.slice(0, 50)}...`)
    
    return summary

  } catch (error) {
    console.error(`âŒ OpenAI APIè°ƒç”¨å¤±è´¥:`, error)
    console.log('ğŸ”„ é™çº§ä½¿ç”¨æ¨¡æ‹Ÿæ‘˜è¦')
    return generateFallbackSummary(content, title, type)
  }
}

// å¤‡ç”¨æ‘˜è¦ç”Ÿæˆï¼ˆå½“APIä¸å¯ç”¨æ—¶ï¼‰
function generateFallbackSummary(content: string, title: string, type: 'quick' | 'detailed'): string {
  const cleanContent = content.replace(/<[^>]*>/g, ' ').trim()
  
  if (type === 'quick') {
    const words = cleanContent.split(/\s+/).slice(0, 15).join(' ')
    return `${title}ï¼š${words}...`
  } else {
    let summary = `æœ¬æ–‡æ¡£ã€Š${title}ã€‹`
    
    const hasCode = cleanContent.includes('ä»£ç ') || cleanContent.includes('function') || cleanContent.includes('class')
    const hasDesign = cleanContent.includes('è®¾è®¡') || cleanContent.includes('ç•Œé¢') || cleanContent.includes('ç”¨æˆ·ä½“éªŒ')
    const hasProcess = cleanContent.includes('æµç¨‹') || cleanContent.includes('æ­¥éª¤') || cleanContent.includes('æ–¹æ³•')
    
    if (hasCode) {
      summary += 'æ·±å…¥æ¢è®¨äº†æŠ€æœ¯å®ç°ç»†èŠ‚ï¼ŒåŒ…å«å…·ä½“çš„ä»£ç ç¤ºä¾‹å’Œè§£å†³æ–¹æ¡ˆã€‚'
    } else if (hasDesign) {
      summary += 'ä»è®¾è®¡è§’åº¦åˆ†æäº†ç”¨æˆ·éœ€æ±‚å’Œç•Œé¢ä¼˜åŒ–æ–¹æ¡ˆï¼Œæä¾›äº†å®ç”¨çš„è®¾è®¡æŒ‡å¯¼ã€‚'
    } else if (hasProcess) {
      summary += 'ç³»ç»Ÿæ¢³ç†äº†å·¥ä½œæµç¨‹å’Œæ“ä½œæ–¹æ³•ï¼Œä¸ºå®é™…æ‰§è¡Œæä¾›äº†è¯¦ç»†æŒ‡å¼•ã€‚'
    } else {
      summary += 'æä¾›äº†æœ‰ä»·å€¼çš„çŸ¥è¯†åˆ†äº«å’Œç»éªŒæ€»ç»“ã€‚'
    }
    
    summary += 'é€‚åˆä½œä¸ºå‚è€ƒèµ„æ–™é•¿æœŸä¿å­˜å’ŒæŸ¥é˜…ã€‚'
    return summary
  }
}

// ä½¿ç”¨AIç”Ÿæˆç« èŠ‚æ‘˜è¦
async function generateSectionSummaries(content: string): Promise<SectionSummary[]> {
  const sections: SectionSummary[] = []
  
  // åŒ¹é…HTMLæ ‡é¢˜æ ‡ç­¾
  const headingRegex = /<h([1-6])[^>]*>(.*?)<\/h[1-6]>/gi
  let match
  let sectionIndex = 1
  
  while ((match = headingRegex.exec(content)) !== null) {
    const level = parseInt(match[1])
    const title = match[2].replace(/<[^>]*>/g, '').trim()
    
    if (title && level <= 3) { // åªå¤„ç†1-3çº§æ ‡é¢˜
      const sectionId = `section-${sectionIndex}`
      const anchor = `#${encodeURIComponent(title)}`
      
      // å°è¯•ä½¿ç”¨AIç”Ÿæˆç« èŠ‚æ‘˜è¦
      let summary = ''
      try {
        const apiKey = process.env.OPENAI_API_KEY
        if (apiKey) {
          const baseUrl = process.env.OPENAI_BASE_URL || 'https://api.openai.com/v1'
          const model = process.env.OPENAI_MODEL_GPT || 'gpt-4o-mini'
          
          const response = await fetch(`${baseUrl}/chat/completions`, {
            method: 'POST',
            headers: {
              'Authorization': `Bearer ${apiKey}`,
              'Content-Type': 'application/json',
            },
            body: JSON.stringify({
              model: model,
              messages: [
                {
                  role: 'user',
                  content: `è¯·ä¸ºæ ‡é¢˜"${title}"ç”Ÿæˆä¸€ä¸ª20å­—ä»¥å†…çš„ä¸€å¥è¯æ¦‚æ‹¬ã€‚ç›´æ¥è¿”å›æ¦‚æ‹¬å†…å®¹ï¼Œä¸è¦å‰ç¼€ã€‚`
                }
              ],
              max_tokens: 50,
              temperature: 0.3,
            }),
          })
          
          if (response.ok) {
            const data = await response.json()
            summary = data.choices[0].message.content.trim()
          }
        }
      } catch (error) {
        console.warn(`ç« èŠ‚æ‘˜è¦ç”Ÿæˆå¤±è´¥: ${title}`, error)
      }
      
      // å¦‚æœAIç”Ÿæˆå¤±è´¥ï¼Œä½¿ç”¨å¤‡ç”¨é€»è¾‘
      if (!summary) {
        if (title.includes('ä»‹ç»') || title.includes('æ¦‚è¿°')) {
          summary = 'ä»‹ç»äº†åŸºæœ¬æ¦‚å¿µå’ŒèƒŒæ™¯ä¿¡æ¯'
        } else if (title.includes('å®ç°') || title.includes('æ–¹æ³•')) {
          summary = 'è¯¦ç»†è¯´æ˜äº†å…·ä½“å®ç°æ–¹æ³•å’Œæ­¥éª¤'
        } else if (title.includes('ç¤ºä¾‹') || title.includes('æ¡ˆä¾‹')) {
          summary = 'é€šè¿‡å®é™…æ¡ˆä¾‹å±•ç¤ºäº†åº”ç”¨åœºæ™¯'
        } else if (title.includes('æ€»ç»“') || title.includes('ç»“è®º')) {
          summary = 'æ€»ç»“äº†å…³é”®è¦ç‚¹å’Œå»ºè®®'
        } else {
          summary = `å…³äº${title}çš„ç›¸å…³å†…å®¹`
        }
      }
      
      sections.push({
        id: sectionId,
        title,
        summary,
        anchor,
        level
      })
      
      sectionIndex++
    }
  }
  
  // å¦‚æœæ²¡æœ‰æ‰¾åˆ°æ ‡é¢˜ï¼Œåˆ›å»ºä¸€ä¸ªé»˜è®¤ç« èŠ‚
  if (sections.length === 0) {
    sections.push({
      id: 'section-1',
      title: 'ä¸»è¦å†…å®¹',
      summary: 'æ–‡æ¡£çš„æ ¸å¿ƒå†…å®¹å’Œä¸»è¦è§‚ç‚¹',
      anchor: '#ä¸»è¦å†…å®¹',
      level: 1
    })
  }
  
  return sections
}

// æ‰§è¡ŒAIåˆ†æ
async function performAnalysis(content: string, title: string): Promise<{
  quickSummary: string
  detailedSummary: string
  sections: SectionSummary[]
}> {
  console.log('ğŸš€ å¼€å§‹AIåˆ†æï¼Œç”Ÿæˆæé€Ÿæ‘˜è¦...')
  
  // å¹¶è¡Œç”Ÿæˆæé€Ÿæ‘˜è¦å’Œæå–ç« èŠ‚
  const [quickSummary, sections] = await Promise.all([
    generateAISummary(content, title, 'quick'),
    generateSectionSummaries(content)
  ])
  
  console.log('ğŸ“ æé€Ÿæ‘˜è¦å®Œæˆï¼Œå¼€å§‹ç”Ÿæˆè¯¦ç»†æ‘˜è¦...')
  
  // ç”Ÿæˆè¯¦ç»†æ‘˜è¦
  const detailedSummary = await generateAISummary(content, title, 'detailed')
  
  console.log('âœ… æ‰€æœ‰AIåˆ†æå®Œæˆ')
  
  return {
    quickSummary,
    detailedSummary,
    sections
  }
}

export async function POST(request: NextRequest) {
  try {
    const { content, title, clipId }: AnalysisRequest = await request.json()
    
    if (!content || !title) {
      return NextResponse.json(
        { error: 'å†…å®¹å’Œæ ‡é¢˜ä¸èƒ½ä¸ºç©º' },
        { status: 400 }
      )
    }

    console.log(`ğŸ§  å¼€å§‹AIåˆ†ææ–‡æ¡£: ${title} (ID: ${clipId})`)
    
    // æ‰§è¡ŒAIåˆ†æ
    const analysisResult = await performAnalysis(content, title)
    
    console.log(`âœ… AIåˆ†æå®Œæˆ: ${title}`)
    console.log(`ğŸ“ æé€Ÿæ‘˜è¦: ${analysisResult.quickSummary}`)
    console.log(`ğŸ“„ è¯¦ç»†æ‘˜è¦: ${analysisResult.detailedSummary.substring(0, 100)}...`)
    console.log(`ğŸ“‹ ç« èŠ‚æ•°é‡: ${analysisResult.sections.length}`)
    
    return NextResponse.json({
      quickSummary: analysisResult.quickSummary,
      detailedSummary: analysisResult.detailedSummary,
      sections: analysisResult.sections
    } as AnalysisResponse)
    
  } catch (error) {
    console.error('âŒ AIåˆ†æå¤±è´¥:', error)
    return NextResponse.json(
      { error: 'AIåˆ†æå¤±è´¥ï¼Œè¯·é‡è¯•' },
      { status: 500 }
    )
  }
} 